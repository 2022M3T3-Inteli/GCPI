{"cells":[{"cell_type":"markdown","metadata":{"id":"8CnbxGG6bVf_"},"source":["<h1>Grupo GCPI - Modelo preditivo Rappi</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foEiyvrQhkiU"},"outputs":[],"source":["#@title Utilização da aplicação {run: \"auto\"}\n","while True:\n","    import pandas as pd\n","    import plotly.express as px\n","    import numpy as np\n","    import datetime\n","    from operator import index\n","    import warnings\n","    from termcolor import colored\n","    warnings.filterwarnings('ignore')\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    from joblib import load\n","    modelo_lgbm = load('/content/drive/MyDrive/Rappi/modelos/modelo_lgbm.model')\n","    modelo_lr = load('/content/drive/MyDrive/Rappi/modelos/modelo_logistic_regression.model')\n","    scaler = load('/content/drive/MyDrive/Rappi/modelos/scaler_modelo_lgbm.scaler')\n","    objetivo = \"Maior certeza do resultado\" #@param [\"Maior numero de possiveis churn\", \"Maior certeza do resultado\"]\n","    if objetivo == 'Maior numero de possiveis churn':\n","        modelo = modelo_lr\n","        modelo_print = \"_modelo_lr\"\n","    else:\n","        modelo = modelo_lgbm\n","        modelo_print = \"_modelo_lgbm\"\n","\n","    try:\n","        print(\"Carregando tabela infos_gerais...\")\n","        df = pd.read_csv(\"/content/drive/MyDrive/Rappi/bases/infos gerais.csv\", usecols={'ID', 'ULTIMO_PEDIDO'})\n","        df[['Date', 'exclude']] = df['ULTIMO_PEDIDO'].str.split('T', expand=True)\n","        df['Date']= df['Date'].astype('datetime64[ns]')\n","        df['Date'].max()\n","        df['Diferenca_Dias'] = df['Date'].max() - df['Date']\n","        for i in  df.select_dtypes(include=['datetime64']).columns.tolist():\n","            df['Diferenca_Dias'] = df['Diferenca_Dias'].astype(str)\n","        df[['dif_num', 'exclude_3']] = df['Diferenca_Dias'].str.split(' ', expand=True)\n","        df['CHURN'] = df['dif_num'].astype(int)\n","        df['CHURN'] = np.where(df['CHURN'] < 21, 0, df['CHURN'])\n","        df['CHURN'] = np.where(df['CHURN'] >= 21, 1, df['CHURN'])\n","        df = df.drop(['ULTIMO_PEDIDO', 'Date', 'exclude', 'Diferenca_Dias', 'dif_num', 'exclude_3'], axis=1)\n","        df_infos = pd.read_csv(\"/content/drive/MyDrive/Bases/infos gerais.csv\", usecols=['ID', 'AUTO_ACEITE', 'GORJETA', 'FRETE_MEDIO', 'TRANSPORTE', 'DATA_NASCIMENTO', 'CIDADE'])\n","        df_infos\n","        df_infos[['YEAR', 'MONTH', 'DAY']] = df_infos['DATA_NASCIMENTO'].str.split('-', expand=True)\n","        date_now = datetime.datetime.now()\n","        year_now = date_now.strftime('%Y')\n","        df_infos['YEAR'] = df_infos['YEAR'].astype(int)\n","        df_infos['AGE'] = int(year_now) - df_infos['YEAR']\n","        df_infos.drop(['DATA_NASCIMENTO', 'YEAR', 'MONTH', 'DAY'], inplace=True, axis=1)\n","        df_infos = df_infos.query(\"TRANSPORTE == 'car' or  TRANSPORTE == 'bicycle' or TRANSPORTE == 'motorbike'\")\n","        df_infos = pd.get_dummies(df_infos, columns=[\"TRANSPORTE\"])\n","        df_infos.loc[df_infos['AUTO_ACEITE'] == True, 'AUTO_ACEITE'] = 1\n","        df_infos.loc[df_infos['AUTO_ACEITE'] == False, 'AUTO_ACEITE'] = 0\n","        df_infos['CIDADE'] = df_infos['CIDADE'].replace(['Sao Paulo', 'Natal', 'Campinas', 'Recife',\n","            'Fortaleza', 'Brasilia', 'Sorocaba', 'Salvador', 'Cotia', 'Santos',\n","            'São Jose', 'Goiânia',\n","            'Ribeirão Preto', 'Porto Alegre', 'Curitiba', 'Pinhais', 'Niterói',\n","            'Diadema', 'Teresina', 'Londrina', 'Guarujá', 'Balneario Camboriú',\n","            'Jundiaí', 'Florianópolis', 'Betim', 'São José do Rio Preto',\n","            'Praia Grande', 'João Pessoa', 'Hortolândia', 'Nova Iguacu',\n","            'Juiz de Fora', 'Maceió', 'São João de Meriti', 'Canoas', 'Poá',\n","            'Uberlandia', 'São Roque', 'Vila Velha', 'Maua', 'Aracaju',\n","            'Paulínia', 'Suzano', 'Novo Hamburgo', 'Parnamirim', 'Belém',\n","            'Lauro de Freitas', 'Valparaíso de Goiás', 'Olinda', '14', '10',\n","            'Jaboatao Dos Guararapes', 'São José dos Campos', 'Itaguaí',\n","            'Itajaí', 'Nilópolis', 'Vinhedo', 'Duque De Caxias', 'Petrópolis',\n","            'Palhoça', 'São Vicente', 'Barueri', 'São José Dos Pinhais',\n","            'Valinhos', 'Jacareí', 'Ipatinga', 'Itupeva', '18', '199',\n","            'Taubaté', 'Sumaré', 'São Gonçalo', 'Rio das Ostras', 'Vassouras',\n","            'Mogi Das Cruzes', '24', '29', 'Ponta Grossa', 'Votorantim', 'Itu',\n","            'Matinhos', 'Teófilo Otoni', 'Mesquita', 'Maricá', 'Piracicaba',\n","            'Vitória', '11', 'Santo Amaro da Imperatriz', 'Atibaia',\n","            'Indaiatuba', '26', 'Barreiras', 'Itabuna', 'Passo Fundo', 'Bauru',\n","            'Sertãozinho', 'Petrolina', 'Ananindeua', 'Canasvieiras', '31',\n","            'Cabo Frio', 'Montes Claros', 'Caruaru', 'Rondonópolis',\n","            'Full Coverage', 'Itapema', 'Anápolis', 'Gramado',\n","            'Poços de Caldas', 'Campo Mourão', 'Feira de Santana', '79',\n","            'São Luis', 'Ourinhos', '61', 'Araraquara', 'Araçatuba',\n","            'Americana', 'Manaus', 'Campina Grande', 'Cariacica', '32',\n","            'Porto Velho', 'Presidente Prudente', 'Pouso Alegre', '30',\n","            'Blumenau', '51', 'Resende', 'Mogi Guaçu', 'Bertioga',\n","            'Balneario Camboriu', 'Vitória da Conquista', 'Nova Friburgo',\n","            'Jaraguá do Sul', '146', 'Sao Jose Dos Pinhais', '5',\n","            'Teresópolis', 'Torres', 'Macaé', '95', 'Sao Vicente', '50',\n","            'Mossoró', 'Pirassununga', 'Macapá', 'Campos dos Goytacazes',\n","            'São Paulo', 'Campo Grande', '282', 'Franca', 'São Carlos',\n","            'Cascavel', 'Imperatriz', 'Rio Branco', '81', 'Xangrila',\n","            'Uberaba', 'Joinville', 'Porto Seguro', 'Sumare', '76', 'Sao Jose',\n","            '48', 'Maringá', '62', 'Caldas Novas', 'Sao Luis', '33', 'Maringa',\n","            'Volta Redonda', 'Limeira', 'Santa Maria', 'Governador Valadares',\n","            'Foz do Iguaçu', 'without_city', '60', 'Rio Grande', '161', '47',\n","            '218', '74', '9', 'FAZENDA RIO GRANDE', 'Playa del Carmen',\n","            'Outras cidades', '94', '156', 'Marilia', 'Sao Goncalo', '49',\n","            '233', 'Sao Carlos', 'SÃO PAULO', 'BELO HORIZINTE',\n","            'RIO DE JANEIRO', '154', '75', '59', '147', 'Cuiabá', '130', '97',\n","            '78', '321', 'Caxias do Sul', 'Full Coverage Brasil', '159',\n","            'Osasco', '16', '252', '149', '13', '12', 'Boa Vista', '126',\n","            '289', 'Rosarito', 'Mexicali', 'Tuxtla Gutierrez', 'Viña del Mar',\n","            'Juliaca', 'Marília', 'Serra', 'Rio Claro'],'Outros')\n","        df_infos = pd.get_dummies(df_infos, columns=['CIDADE'])\n","        df = df.merge(df_infos, how='inner', left_on= 'ID', right_on='ID')\n","        print(colored(\"!!!!Sucesso ao obter tabela infos_gerais!!!!\", \"green\"))\n","        print(\"Carregando tabela Orders Done e Cancel...\")\n","    except:\n","        print(colored(\"!!!!Erro ao obter tabela infos_gerais!!!!\", \"red\"))\n","        break\n","\n","    try:\n","        df_orders = pd.read_csv(\"/content/drive/MyDrive/Rappi/bases/Ordens Done e Cancel.csv\", dtype={\"STOREKEEPER_ID\": \"int32\", \"ORDERS_DONE\": \"int16\", \"ORDERS_CANCEL\": \"int16\",  \"CANCELS_OPS_RT\": \"int16\"})\n","        df_orders['CANCEL_RATE'] = (df_orders['ORDERS_CANCEL'] + df_orders['CANCELS_OPS_RT']) / (df_orders['ORDERS_DONE'] + df_orders['ORDERS_CANCEL'] + df_orders['CANCELS_OPS_RT'])\n","        df_orders = df_orders.drop(columns=['ORDERS_CANCEL', 'CANCELS_OPS_RT', 'ORDERS_DONE'])\n","        df = df.merge(df_orders, how='inner', left_on= 'ID', right_on='STOREKEEPER_ID')\n","        df.drop('STOREKEEPER_ID', inplace=True, axis=1)\n","        df_orders = ''\n","        print(colored(\"!!!!Sucesso ao obter tabela Ordens Done e Cancel!!!!\", \"green\"))\n","        print(\"Carregando tabela Incidentes_Regras RT...\")\n","    except:\n","        print(colored(\"Erro ao obter tabela Ordens Done e Cancel\", \"red\"))\n","        break\n","\n","    try:\n","        df_incidentes = pd.read_csv(\"/content/drive/MyDrive/Rappi/bases/Incidentes_Regras RT.csv\", usecols=['STOREKEEPER_ID','PUNISHMENT_MINUTES'], dtype={\"STOREKEEPER_ID\": \"int32\", \"PUNISHMENT_MINUTES\": \"int32\"})\n","        df_incidentes = df_incidentes.groupby('STOREKEEPER_ID')['PUNISHMENT_MINUTES'].agg(['sum','count'])\n","        df_incidentes['STOREKEEPER_ID'] = df_incidentes.index\n","        df_incidentes.rename(columns = {'sum':'MINUTES_PUNISHMENTS', 'count':'NUM_PUNISHMENTS'}, inplace = True)\n","        df_incidentes = df_incidentes.reset_index(drop=True)\n","        df_incidentes = df_incidentes.astype(int)\n","        df = df.merge(df_incidentes, how='left', left_on= 'ID', right_on='STOREKEEPER_ID')\n","        df.drop('STOREKEEPER_ID', inplace=True, axis=1)\n","        df[['MINUTES_PUNISHMENTS', 'NUM_PUNISHMENTS']] = df[['MINUTES_PUNISHMENTS', 'NUM_PUNISHMENTS']].fillna(0)\n","        df_incidentes = ''\n","        indexNames = df[df['MINUTES_PUNISHMENTS'] >= 21600000].index\n","        df = df.drop(indexNames)\n","        indexNames = \"\"\n","        print(colored(\"!!!!Sucesso ao obter tabela Incidentes_Regras RT!!!!\", \"green\"))\n","        print(\"Carregando tabela Distance...\")\n","    except:\n","        print(colored(\"Erro ao obter tabela Incidentes_Regras RT\", \"red\"))\n","        break\n","\n","    try:\n","        df_distance = pd.read_csv(\"/content/drive/MyDrive/Rappi/bases/Distance.csv\", usecols=['STOREKEEPER_ID', 'DISTANCE_TO_USER'])\n","        df_distance = df_distance.dropna()\n","        df_distance['STOREKEEPER_ID'].isna().sum()\n","        df_distance['STOREKEEPER_ID'] = df_distance['STOREKEEPER_ID'].astype(int)\n","        deliveries_count = df_distance['STOREKEEPER_ID'].value_counts()\n","        deliveries_count = deliveries_count.to_frame()\n","        deliveries_count.rename(columns={'STOREKEEPER_ID': 'DELIVERIES_COUNT'}, inplace = True)\n","        df_distance = df_distance.groupby('STOREKEEPER_ID').sum()\n","        distance_total = deliveries_count.merge(df_distance, how='inner', left_index=True, right_on='STOREKEEPER_ID')\n","        distance_total['DISTANCE_MEDIAN'] = distance_total['DISTANCE_TO_USER']/distance_total['DELIVERIES_COUNT']\n","        distance_total = distance_total.round({\"DISTANCE_MEDIAN\":1})\n","        distance_total.drop('DISTANCE_TO_USER', inplace=True, axis=1)\n","        distance_total['STOREKEEPER_ID'] = distance_total.index\n","        distance_total = distance_total.reset_index(drop=True)\n","        df = df.merge(distance_total, how='inner', left_on= 'ID', right_on='STOREKEEPER_ID')\n","        df.drop('STOREKEEPER_ID', inplace=True, axis=1)\n","        df_distance = ''\n","\n","        df_frete = df[['ID','FRETE_MEDIO']]\n","        df_frete.rename(columns={'ID': 'STOREKEEPER_ID'}, inplace = True)\n","        df_frete.rename(columns={'FRETE_MEDIO': 'SHIPPING_MEDIAN'}, inplace = True)\n","        Rts_frete_per_distance = df_frete.merge(distance_total, how='inner', left_on='STOREKEEPER_ID', right_on='STOREKEEPER_ID')\n","        Rts_frete_per_distance = Rts_frete_per_distance.drop_duplicates(keep='first')\n","        Rts_frete_per_distance['SHIPPING_PER_DISTANCE'] = Rts_frete_per_distance['SHIPPING_MEDIAN']/Rts_frete_per_distance['DISTANCE_MEDIAN']\n","        Rts_frete_per_distance.drop(['DELIVERIES_COUNT', 'DISTANCE_MEDIAN', 'SHIPPING_MEDIAN'], inplace=True, axis=1)\n","        df = df.merge(Rts_frete_per_distance, how='inner', left_on= 'ID', right_on='STOREKEEPER_ID')\n","        df.drop('STOREKEEPER_ID', inplace=True, axis=1)\n","        df.drop('FRETE_MEDIO', inplace=True, axis=1)\n","        df.drop('DISTANCE_MEDIAN', inplace=True, axis=1)\n","        Rts_frete_per_distance = ''\n","        df_frete = ''\n","        df_infos = ''\n","        print(colored(\"!!!!Sucesso ao obter tabela Distance!!!!\", \"green\"))\n","        print(\"Processando dados e carregando modelos...\")\n","    except:\n","        print(colored(\"Erro ao obter tabela Distance\", \"red\"))\n","        break\n","\n","    try:\n","        df = df.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n","        df = df.dropna()\n","        df['AUTO_ACEITE'] = df['AUTO_ACEITE'].astype('int8')\n","        colunas = ['GORJETA', 'AGE', 'MINUTES_PUNISHMENTS', 'NUM_PUNISHMENTS', 'DELIVERIES_COUNT', 'SHIPPING_PER_DISTANCE']\n","        x = df.drop(columns=['ID', 'CHURN'])\n","        x[colunas] = scaler.transform(x[colunas])\n","        lista = modelo.predict_proba(x)\n","        x['churn'] = modelo.predict(x)\n","        df['churn'] = x['churn']\n","        df = df.drop(columns=['AUTO_ACEITE',\t'GORJETA',\t'AGE',\t'TRANSPORTE_bicycle',\t'TRANSPORTE_car',\t'TRANSPORTE_motorbike',\t'CIDADE_Belo Horizonte',\t'CIDADE_Grande São Paulo',\t'CIDADE_Outros'\t,'CIDADE_Rio de Janeiro',\t'CANCEL_RATE'\t,'MINUTES_PUNISHMENTS'\t,'NUM_PUNISHMENTS'\t,'DELIVERIES_COUNT',\t'SHIPPING_PER_DISTANCE'])\n","        df.reset_index(drop=True, inplace=True)\n","        array_vazio= []\n","        for array_pequenas in lista:\n","            if array_pequenas[1] <= 0.2:\n","                array_vazio.append(1)\n","            elif array_pequenas[1] > 0.2 and array_pequenas[1] <= 0.4:\n","                array_vazio.append(2)\n","            elif array_pequenas[1] > 0.6 and array_pequenas[1] <= 0.8:\n","                array_vazio.append(4)\n","            elif array_pequenas[1] > 0.8:\n","                array_vazio.append(5)\n","            else: \n","                array_vazio.append(3)\n","        new_df = pd.DataFrame(array_vazio)\n","        df[\"PROBABILIDADE_CHURN\"] = new_df[0]\n","        df['FILTRO'] = df['churn'] - df['CHURN']\n","        df = df.sort_values(by=['FILTRO'], ascending=False)\n","        df = df.drop(columns=['FILTRO'])\n","        df = df.replace({'PROBABILIDADE_CHURN': {1: 'Muito Baixa', 2: 'Baixa', 3: 'Média', 4: 'Alta', 5: 'Muito Alta'}})\n","        df.columns = ['ID', 'RT_INATIVO', 'PREVISTO_CHURN', 'PROBABILDADE_CHURN']\n","        df = df.replace({'RT_INATIVO': {0: 'Não', 1: 'Sim'}, 'PREVISTO_CHURN': {0: 'Não', 1: 'Sim'}})\n","        print(colored(\"!!!!Sucesso ao processar dados e aplicar o modelo!!!! \\n\", \"green\"))\n","    except:\n","        print(colored(\"Erro ao processar dados e aplicar o modelo \\n\", \"red\"))\n","        break\n","\n","    import ipywidgets as widgets\n","    from IPython.display import display\n","    button_csv = widgets.Button(description=\"Exportar CSV\")\n","    button_excel = widgets.Button(description=\"Exportar XLSX\")\n","    output_csv = widgets.Output()\n","    output_excel = widgets.Output()\n","    def on_button_clicked_csv(b):\n","        with output_csv:\n","            print(\"Aguarde a conversão...\")\n","            df.to_csv('/content/drive/MyDrive/Rappi/churn' + modelo_print + '.csv', index=False)\n","            print(colored(\"!!!!CSV criado com sucesso na pasta do projeto!!!! \\n\", \"green\"))\n","    def on_button_clicked_excel(b):\n","        with output_excel:\n","            print(\"Aguarde a conversão...\")\n","            df.to_excel('/content/drive/MyDrive/Rappi/churn' + modelo_print + '.xlsx', index=False)\n","            print(colored(\"!!!!Planilha criada com sucesso na pasta do projeto!!!! \\n\", \"green\"))\n","    button_csv.on_click(on_button_clicked_csv)\n","    button_excel.on_click(on_button_clicked_excel)\n","    display(button_csv, output_csv)\n","    display(button_excel, output_excel)\n","    break"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1NWJwp2ocvhPxl6n9z6JMVD3kt1CbIB1Z","timestamp":1664216466570},{"file_id":"1Eodg5-ZOa1tWILvloK-K2XUHvR4XGlWm","timestamp":1663905622853},{"file_id":"1STUvzITl4hOoeZHQM7obDE9K6vkkmeh0","timestamp":1663179253655},{"file_id":"1Pz7l748KX6PowZon0cwiTHgdxQVEI14w","timestamp":1662488828047},{"file_id":"107sg0bQVziaJ-vYL8T2gMsEuQg7MAb1x","timestamp":1662424750300},{"file_id":"1C3qrcC_Cg-xmA3HJwIrMJKLegEQic-5v","timestamp":1661967365863},{"file_id":"1Y6JqR-tiOlqiQFbTtZ7sWBq1TDwybH6O","timestamp":1661451387003},{"file_id":"1zTUjDyFLM2Zvtsgu3FhAcgBdpGYqUrZS","timestamp":1660747595452}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}